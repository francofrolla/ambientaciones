{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regulation-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero la carpeta temporal\n",
    "import os \n",
    "from os import path\n",
    "\n",
    "dirName = 'temp'\n",
    "\n",
    "if path.exists(\"temp\") == False:\n",
    " os.mkdir(dirName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ready-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import json\n",
    "from ee import oauth\n",
    "\n",
    "refresh_token = \"1//0hhFAc7SYpYZ6CgYIARAAGBESNwF-L9IrrKQqIqscZ4fxIYDRSSh3pElBI7E9dQSmSjJL9xK-wbIgjaD-wGYErrcagerwNqtn8tE\"\n",
    "\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "clave = Credentials(\n",
    "        None,\n",
    "        refresh_token=refresh_token,\n",
    "        token_uri=oauth.TOKEN_URI,\n",
    "        client_id=oauth.CLIENT_ID,\n",
    "        client_secret=oauth.CLIENT_SECRET,\n",
    "        scopes=oauth.SCOPES)\n",
    "\n",
    "\n",
    "\n",
    "ee.Initialize(credentials = clave)\n",
    "\n",
    "#pip install voila\n",
    "#pip install ipyfilechooser\n",
    "#import shutil\n",
    "#dst_path = \"/app/.heroku/python/lib/python3.8/site-packages/ee/oauth.py\"\n",
    "#src_file = \"/app/oauth.py\"\n",
    "#shutil.move(src_file, dst_path)\n",
    "\n",
    "from io import StringIO\n",
    "import geemap\n",
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#conda install mamba -c conda-forge\n",
    "#conda install xarray_leaflet -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-reggae",
   "metadata": {},
   "source": [
    "##Calculo de Tasa de crecimiento para cultivos mediante imagenes Sentinel. \n",
    "###frolla.franco@inta.gob.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "portable-rebound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d838b9f0ff4f32ad6ffb5796b9c057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-36, -63], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#import geemap.eefolium as geemap\n",
    "Map = geemap.Map(center=[-36,-63], zoom=4)\n",
    "url = 'http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}'\n",
    "Map.add_tile_layer(url, name='Google Map', attribution='Google')\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "phantom-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c001e215c969486b9be03da4206a230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.geojson', button_style='primary', description='GeoJson')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "uploader = widgets.FileUpload(button_style='primary',  accept='.geojson',description=\"GeoJson\")\n",
    "display(uploader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "every-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792155f8f7114b37ac6b253bad964de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Agregar Lote', style=ButtonStyle(), tooltip='Click …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import config\n",
    "import ee\n",
    "import json\n",
    "import tempfile\n",
    "import geopandas as gpd\n",
    "from ipywidgets import Checkbox, HBox, VBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "subirkml = widgets.Button(\n",
    "    description='Agregar Lote',\n",
    "    button_style='primary',\n",
    "    tooltip='Click para buscar imagenes',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def subirkml_clicked(b):\n",
    "    \n",
    " with output:\n",
    "        print(\"Iniciando...\")\n",
    " llaves = uploader.value.keys()\n",
    " \n",
    " if llaves.__len__() != 0:\n",
    "    try:\n",
    "        for key in llaves:\n",
    "          nombre_archivo = key\n",
    "          config.nombrelote = key\n",
    "\n",
    "        lote = json.loads(uploader.value[nombre_archivo][\"content\"])\n",
    "        gdf = gpd.GeoDataFrame.from_features(lote[\"features\"])\n",
    "\n",
    "        if (\"CULTIVOS\" in list(gdf.columns)) == False:\n",
    "         with output:\n",
    "            print(\"No se encontro la columna CULTIVOS, por favor revise el geojson o visite https://github.com/francofrolla/TCpasturasSentinel\")\n",
    "\n",
    "        if (\"CULTIVOS\" in list(gdf.columns)) == True:\n",
    "            with output:\n",
    "             print(\"Se encontro la columna CULTIVOS\")\n",
    "\n",
    "            permitidos = [\"VERDEO INVIERNO\",\n",
    "            \"CN+AGRO\",\n",
    "            \"CN+FEST\",\n",
    "            \"CAMPO NATURAL\",\n",
    "            \"PASTURA ALFALFA\",\n",
    "            \"PASTURA CONSOCIADA\",\n",
    "            \"PASTURA AGROPIRO\",\n",
    "            \"ALFALFA PURA\",\n",
    "            \"PASTURA FESTUCA\",\n",
    "            \"VERDEO SORGO\",\n",
    "            \"VERDEO MAIZ\"\n",
    "            ]\n",
    "\n",
    "            valoresencolumna = list(gdf[\"CULTIVOS\"].values)\n",
    "            myset = set(valoresencolumna)\n",
    "\n",
    "            for cultivo in list(myset):\n",
    "                if (cultivo in permitidos) == True:\n",
    "                    with output:\n",
    "                        print(cultivo, \"valor valido de forraje\")\n",
    "                if (cultivo in permitidos) == False:\n",
    "                    with output:\n",
    "                        print(cultivo, \"valor NO valido de forraje, controle el geojson o visite https://github.com/francofrolla/TCpasturasSentinel\")\n",
    "\n",
    "            gdf.crs = \"EPSG:4326\"\n",
    "            gdf.to_file(\"temp/datosausar.shp\")\n",
    "\n",
    "            ruta = \"temp/datosausar.shp\"\n",
    "\n",
    "            df = gpd.read_file(ruta)\n",
    "            direccion = \"temp\"\n",
    "            rutafinal = direccion+\"/\"+\"salida1.geojson\"\n",
    "            df = df.to_crs(\"EPSG:4326\")\n",
    "            df.to_file(rutafinal, driver='GeoJSON')\n",
    "\n",
    "           # try:\n",
    "           #  df.to_file(rutafinal, driver='GeoJSON')\n",
    "           #  with output:\n",
    "           #    print(\"Archivo guardado\")\n",
    "           # except:\n",
    "           #  with output:\n",
    "           #    print(\"no a funcionado\")\n",
    "            # try:\n",
    "             # f=open(rutafinal, \"r\")\n",
    "            # except:\n",
    "             # with output:\n",
    "             #   print(\"no a hay archivo\")\n",
    "\n",
    "\n",
    "            #Genero la feature collection\n",
    "            listaobjeto=ee.List([])\n",
    "            f=open(rutafinal, \"r\")\n",
    "            contents =f.read()\n",
    "            geojson1 = contents.replace(\", 0.0\", \"\")\n",
    "            d = json.loads(geojson1)\n",
    "            for a in range(0,len(d['features'])):\n",
    "              geometria = ((d['features'][a][\"geometry\"][\"coordinates\"]))\n",
    "              propiedades = d[\"features\"][a][\"properties\"]\n",
    "              objeto = ee.Feature(ee.Geometry.Polygon(geometria[0]), propiedades)\n",
    "              listaobjeto = listaobjeto.add(objeto)\n",
    "\n",
    "            fet = ee.FeatureCollection(listaobjeto)\n",
    "            config.fet = fet\n",
    "            f.close()\n",
    "\n",
    "            df['dissolvefield'] = 1\n",
    "            df1 = df.dissolve(by='dissolvefield')\n",
    "            df1 = df1[\"geometry\"]\n",
    "            config.df1 = df1\n",
    "            rutafinal2 = direccion+\"/\"+\"salida2.geojson\"\n",
    "            df1.to_file(rutafinal2, driver='GeoJSON')\n",
    "\n",
    "            f=open(rutafinal, \"r\")\n",
    "            contents =f.read()\n",
    "            geojson1 = contents.replace(\", 0.0\", \"\")\n",
    "            f.close()\n",
    "             \n",
    "            d = json.loads(geojson1) \n",
    "            lote = config.fet.geometry().dissolve()\n",
    "            Map.addLayer(lote,{}, \"Lotes\")\n",
    "            Map.centerObject(lote, 14)\n",
    "            \n",
    "            #Se grafica lote por lote\n",
    "            #for poligono in d['features']:\n",
    "            #  geometria = (poligono[\"geometry\"][\"coordinates\"])\n",
    "            #  nombre = (poligono[\"properties\"][\"NAME\"])\n",
    "            #  lote = ee.Geometry.Polygon(geometria[0])\n",
    "            #  Map.addLayer(lote,{}, nombre)\n",
    "            #  Map.centerObject(lote, 14)\n",
    "            \n",
    "            with output:\n",
    "             print(\"Se graficaron los lotes\")\n",
    "\n",
    "             #if 1 == 1:    \n",
    "             # d = json.loads(geojson1)\n",
    "             # geometria = (d['features'][0][\"geometry\"][\"coordinates\"])\n",
    "             # lote = ee.Geometry.Polygon(geometria[0])\n",
    "             # config.lote = lote\n",
    "             # Map.addLayer(lote,{}, 'Layer name')\n",
    "             # Map.centerObject(lote, 14)\n",
    "             # Map.addLayerControl()\n",
    "              #Map\n",
    "             # f.close()\n",
    "             #else:\n",
    "             # texto.value = \"No se selecciono un archivo valido\"\n",
    "    except:\n",
    "     with output:\n",
    "         print(\"No se cargo un archivo valido, por favor revise el geojson o visite https://github.com/francofrolla/TCpasturasSentinel \")\n",
    "    \n",
    "    \n",
    " if llaves.__len__() == 0:\n",
    "    with output:\n",
    "     print(\"No se selecciono ningun archivo\")\n",
    "     \n",
    " \n",
    "  \n",
    "\n",
    "subirkml.on_click(subirkml_clicked)\n",
    "HBox([subirkml,output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "global-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da46ec6b35fc49d896d73007546c0938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Buscar Imagenes', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from ipywidgets import Checkbox, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "import ipyleaflet\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "from datetime import date\n",
    "import config\n",
    "\n",
    "boton0 = widgets.Button(description='Buscar Imagenes',button_style='primary')\n",
    "selfechas = widgets.Dropdown(\n",
    "    options=config.listaid,\n",
    "    value=config.listaid[0],\n",
    "    description='Seleccione Fecha:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def buscar_imagenes(b):\n",
    "    start_date = date.today()\n",
    "    fecha = start_date.strftime(\"%Y-%m-%d\")\n",
    "    fecha_inicio = ee.Date(fecha);\n",
    "\n",
    "\n",
    "    #fecha_inicio = ee.Date(fecha);\n",
    "    #fecha_inicio = ee.Date('2020-03-15')\n",
    "    fecha_fin =  fecha_inicio.advance(-25, 'day')\n",
    "\n",
    "\n",
    "    #lote = config.lote\n",
    "    lote = config.fet.geometry()\n",
    "\n",
    "    loteentero = lote\n",
    "    lote = lote.buffer(-35)\n",
    "\n",
    "    coleccionfiltrada = ee.ImageCollection('COPERNICUS/S2').filterBounds(lote).filterDate(fecha_fin,fecha_inicio)\n",
    "\n",
    "    lista = coleccionfiltrada.toList(coleccionfiltrada.size())\n",
    "    imagen = ee.Image(lista.get(0))\n",
    "    lista = lista.add(imagen)\n",
    "\n",
    "    def detectar_duplicador(imagen):\n",
    "        esduplicado = ee.String(\"\")\n",
    "        numero = lista.indexOf(imagen)\n",
    "        imagen1 = ee.Image(lista.get(numero.add(1)))\n",
    "        #Compare the image(0) in the ImageCollection with the image(1) in the List\n",
    "        fecha1 = imagen.date().format(\"Y-M-d\")\n",
    "        fecha2 = imagen1.date().format(\"Y-M-d\")\n",
    "        estado = ee.Algorithms.IsEqual(fecha1,fecha2)\n",
    "        esduplicado = ee.String(ee.Algorithms.If(estado,\"duplicado\",\"no duplicado\"));\n",
    "        imagen = imagen.set(\"duplicado\", esduplicado)\n",
    "        return imagen\n",
    "\n",
    "    coleccionfiltrada = coleccionfiltrada.map(lambda image: detectar_duplicador(image))\n",
    "    coleccionfiltrada = coleccionfiltrada.filter(ee.Filter.eq('duplicado', \"no duplicado\"))\n",
    "\n",
    "    def fechas(image):\n",
    "         fecha = image.select(\"B3\").date().format(\"YYYY-MM-dd\")\n",
    "         image = image.set(\"fecha\",fecha)\n",
    "         return image\n",
    "\n",
    "    coleccionfiltrada = coleccionfiltrada.map(lambda imagen: fechas(imagen))\n",
    "\n",
    "    with out:\n",
    "     print(\"Armando diccionario y descargando datos del servidor\")\n",
    "\n",
    "    fechas = coleccionfiltrada.aggregate_array(\"fecha\")\n",
    "    id = coleccionfiltrada.aggregate_array(\"system:index\")\n",
    "\n",
    "    test_dict = ee.Dictionary.fromLists(['fechas', 'id'], [fechas, id])\n",
    "    featureCollection = ee.FeatureCollection([ee.Feature(None, test_dict)])\n",
    "\n",
    "    link = featureCollection.getDownloadURL(filetype=\"CSV\", selectors=None, filename=None)\n",
    "    #Generamos el diccionario con los valores.\n",
    "    import csv, urllib.request\n",
    "    response = urllib.request.urlopen(link)\n",
    "    lines = [l.decode('utf-8') for l in response.readlines()]\n",
    "    reader = csv.DictReader(lines)\n",
    "\n",
    "    #import ast\n",
    "    #for row in reader:\n",
    "    # x = row[\"fechas\"]\n",
    "    # fechas = x\n",
    "    # x1 = row[\"id\"]\n",
    "    # id = x1\n",
    "        \n",
    "    \n",
    "    data = list(reader)\n",
    "    # Converting string to list\n",
    "    fechas_cliente = data[0][\"fechas\"].strip('][').split(', ')\n",
    "    id_cliente = data[0][\"id\"].strip('][').split(', ')\n",
    "    \n",
    "    #config.fechas_cliente = fechas_cliente\n",
    "    config.id_cliente = id_cliente\n",
    "\n",
    "    fechas_cliente = map(str, fechas_cliente)\n",
    "    fechas = list(fechas_cliente)\n",
    "\n",
    "    #id_cliente = map(str, id_cliente)\n",
    "    #id = list(id_cliente)\n",
    "    \n",
    "    config.fechas = fechas\n",
    "\n",
    "    config.listaid=[]\n",
    "\n",
    "    #Acomodo para generar la lista de ids.     \n",
    "    #li = (id.split(\"[\"))\n",
    "    #ids = (li[1].split(\"]\"))[0]\n",
    "    #ids = list(ids.split(\",\"))\n",
    "\n",
    "    for a in id_cliente:\n",
    "      a = a.strip()\n",
    "      b = \"COPERNICUS/S2/\"+a\n",
    "      config.listaid.append(b)\n",
    "\n",
    "    #Acomodo para generar lista de fechas\n",
    "    #li = (fechas.split(\"[\"))\n",
    "    #ids = (li[1].split(\"]\"))[0]\n",
    "    #ids = list(ids.split(\",\"))\n",
    "\n",
    "   # for a in ids:\n",
    "    #  a = a.strip()\n",
    "   #   config.fechas.append(b)\n",
    "    #Asigno las fechas al drowmenu\n",
    "    selfechas.index = None\n",
    "    selfechas.options=config.listaid\n",
    "    \n",
    "    with out:\n",
    "     print(\"Busqueda Terminada\")\n",
    "    \n",
    "\n",
    "boton0.on_click(buscar_imagenes)\n",
    "\n",
    "HBox([boton0,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "superior-photography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3cffaa83394fa38791f29b0d79ddda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Seleccione Fecha:', index=8, options=('COPERNICUS/S2/20210503T135111_2021…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Checkbox, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "import ipyleaflet\n",
    "\n",
    "#CONSTANTES DEL MAPA\n",
    "#palette = ['#FFFFFF', '#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']\n",
    "#Map.add_colorbar_branca(colors=palette,vmin=0.2,vmax=0.7)\n",
    "output_widget = widgets.Output(layout={'border': '1px solid black',\"font_weight\": \"5px\"})\n",
    "output_control = ipyleaflet.WidgetControl(widget=output_widget, position='bottomleft')\n",
    "Map.add_control(output_control)\n",
    "\n",
    "#selfechas = widgets.Dropdown(\n",
    "#    options=config.listaid,\n",
    "#    value=config.listaid[0],\n",
    "#    description='Seleccione Fecha:',\n",
    "#    disabled=False,\n",
    "#)\n",
    "\n",
    "boton1 = widgets.Button(description='Graficar NDVI',button_style='primary')\n",
    "boton2 = widgets.Button(description='Graficar',button_style='primary')\n",
    "\n",
    "out1 = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def graficar_onclicked(b):\n",
    " #Borro lo anterior\n",
    " with out:\n",
    "  clear_output()\n",
    " laimagen = ee.Image(selfechas.value)\n",
    " escena = laimagen.clip(config.fet.geometry().dissolve())\n",
    " escena = escena.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    " escena = escena.select([\"NDVI\"])\n",
    "\n",
    " params = escena.reduceRegion(\n",
    "           reducer= ee.Reducer.percentile([10, 90]), \n",
    "           geometry= config.fet.geometry().dissolve(), \n",
    "           scale= 10\n",
    "           )\n",
    "\n",
    " parametros = params.getInfo()\n",
    " min_valor = [parametros['NDVI_p10']]\n",
    " max_valor = [parametros['NDVI_p90']]\n",
    "\n",
    " vis_params = {\n",
    "              'min': min_valor,\n",
    "              'max': max_valor,\n",
    "              'palette': ['FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901', '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01', '012E01', '011D01', '011301']}\n",
    "\n",
    " with out1:\n",
    "  texto = \"Graficando imagen \"+str(selfechas.value)+\" NDVI min:\"+ str(min_valor) +\" NDVI max:\"+ str(max_valor) \n",
    "  print(texto)\n",
    "\n",
    " Map.addLayer(escena, vis_params, selfechas.value)\n",
    "\n",
    " with output_widget:\n",
    "  clear_output()\n",
    "  print(texto)\n",
    "\n",
    "def graficar_cv_onclicked(b):\n",
    " #Borro lo anterior\n",
    " with out:\n",
    "  clear_output()\n",
    " laimagen = ee.Image(selfechas.value)\n",
    " escena = laimagen.clip(config.fet.geometry().dissolve().buffer(1000))\n",
    " \n",
    "\n",
    " params = escena.select([\"B4\",\"B3\",\"B2\"]).reduceRegion(\n",
    "      reducer= ee.Reducer.percentile([5, 95]), \n",
    "      geometry= config.fet.geometry().dissolve().buffer(1000), \n",
    "      scale= 10,\n",
    "      )\n",
    " parametros = params.getInfo()\n",
    " min_escena = [parametros['B4_p5'], parametros['B3_p5'], parametros['B2_p5']]\n",
    " max_escena = [parametros['B4_p95'], parametros['B3_p95'], parametros['B2_p95']]\n",
    "\n",
    " vis_params = {\n",
    "              'bands':['B4', 'B3', 'B2'],\n",
    "              'min': min_escena,\n",
    "              'max': max_escena,\n",
    "               }\n",
    "\n",
    " with out1:\n",
    "  texto = \"Graficando imagen \"+str(selfechas.value) \n",
    "  print(texto)\n",
    "\n",
    " Map.addLayer(escena, vis_params, selfechas.value)\n",
    "\n",
    " with output_widget:\n",
    "  clear_output()\n",
    "  print(texto)\n",
    "  \n",
    "\n",
    "boton1.on_click(graficar_onclicked)\n",
    "boton2.on_click(graficar_cv_onclicked)\n",
    "\n",
    "HBox([selfechas,boton1,boton2,out1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Checkbox, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "import ipyleaflet\n",
    "import ast\n",
    "\n",
    "boton2 = widgets.Button(description='Calcular TC',button_style='primary')\n",
    "out2 = widgets.Output()\n",
    "\n",
    "\n",
    "def calcular_tc(b):\n",
    "    with out2:\n",
    "        print(\"Iniciando calculo\")\n",
    "    import config\n",
    "    laimagen = ee.Image(selfechas.value)\n",
    "    #escena = laimagen.clip(config.lote)\n",
    "    escena = laimagen\n",
    "\n",
    "    escena = escena.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    def addArea(feature):\n",
    "     feature = feature.set({\"areaHa\": feature.geometry().area().divide(100 * 100)});\n",
    "     return feature\n",
    "\n",
    "    config.fet = config.fet.map(addArea);\n",
    "\n",
    "    # Agregar la media de cada imagen\n",
    "    resumen = escena.select(\"NDVI\").reduceRegions(config.fet, ee.Reducer.mean())\n",
    "\n",
    "    medias = resumen.aggregate_array(\"mean\")\n",
    "    indexsat = resumen.aggregate_array(\"system:index\")\n",
    "    cultivos = resumen.aggregate_array(\"CULTIVOS\")\n",
    "    areaHa = resumen.aggregate_array(\"areaHa\")\n",
    "\n",
    "\n",
    "    test_dict = ee.Dictionary.fromLists(['indice', 'medias',\"CULTIVOS\",\"areaHa\"], [indexsat, medias,cultivos,areaHa])\n",
    "    featureCollection = ee.FeatureCollection([ee.Feature(None, test_dict)])\n",
    "    \n",
    "    with out2:\n",
    "        print(\"Consultando datos del servidor\")\n",
    "\n",
    "    link = featureCollection.getDownloadURL(filetype=\"CSV\", selectors=None, filename=None)\n",
    "    #Generamos el diccionario con los valores.\n",
    "    import csv, urllib.request\n",
    "    response = urllib.request.urlopen(link)\n",
    "    lines = [l.decode('utf-8') for l in response.readlines()]\n",
    "    reader = csv.DictReader(lines)\n",
    "    \n",
    "    data = list(reader)\n",
    "    \n",
    "    # Converting string to list\n",
    "    indice_cliente = data[0][\"indice\"].strip('][').split(', ')\n",
    "    medias_cliente = data[0][\"medias\"].strip('][').split(', ')\n",
    "    cultivo_cliente = data[0][\"CULTIVOS\"].strip('][').split(', ')\n",
    "    areaHa_cliente = data[0][\"areaHa\"].strip('][').split(', ')\n",
    "\n",
    "    \n",
    "    areaHa_cliente = map(float, areaHa_cliente)\n",
    "    areaHa_cliente = list(areaHa_cliente)\n",
    "    \n",
    "    medias_cliente = map(float, medias_cliente)\n",
    "    medias_cliente = list(medias_cliente)\n",
    "\n",
    "    indice_cliente = map(int, indice_cliente)\n",
    "    indice_cliente = list(indice_cliente)\n",
    "    \n",
    "    \n",
    "\n",
    "    import pandas as pd\n",
    "    ndvis = pd.DataFrame(list(zip(indice_cliente, medias_cliente,cultivo_cliente,areaHa_cliente)),columns =['Indice', 'MediaNDVI', 'CULTIVOS',\"areaHa\"])\n",
    "    \n",
    "  \n",
    "    config.ndvis = ndvis\n",
    "    \n",
    "    with out2:\n",
    "        print(\"Datos obtenidos\")\n",
    "\n",
    "    #EN ESTA CELDA SE CALCULA LA RADIACION POR FECHA LATITUD Y LONGITUD\n",
    "    #Cargo los datos de radiacion\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    radiacion = pd.read_csv(os.getcwd()+\"/Radiación incidente2.csv\",sep=\";\")\n",
    "\n",
    "    #Extraigo coordendas del shapefile cargado\n",
    "    with out2:\n",
    "        print(\"Consultando RF\")\n",
    "\n",
    "\n",
    "    x = config.df1.centroid.x\n",
    "    y = config.df1.centroid.y\n",
    "\n",
    "    import numpy as np\n",
    "    latitudes = np.arange(-48, -18, 0.2)\n",
    "    longitudes = np.arange(-68, -52, 0.4)\n",
    "\n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    valor_lat = (find_nearest(latitudes, y.values[0]))\n",
    "    valor_lat = round(valor_lat, 1)\n",
    "\n",
    "    valor_long = (find_nearest(longitudes, x.values[0]))\n",
    "    valor_long = round(valor_long, 1)\n",
    "\n",
    "    #Aca tendria que conseguir las fechas de la imagen selecionada\n",
    "    indice = config.listaid.index(selfechas.value)\n",
    "    fecha = config.fechas[indice]\n",
    "\n",
    "    mes = int(fecha.split('-')[1])\n",
    "    dia = int(fecha.split('-')[2])\n",
    "\n",
    "\n",
    "    radiacion_filtrada = radiacion[radiacion['MES'] == mes]\n",
    "    radiacion_filtrada = radiacion_filtrada.iloc[(radiacion_filtrada['DIA']-dia).abs().argsort()[:76]]\n",
    "    radiacion_filtrada = radiacion_filtrada.iloc[(radiacion_filtrada['lat']-y.values[0]).abs().argsort()[:1]]\n",
    "    radiacion_filtrada.iloc[(radiacion_filtrada['lat']-y.values[0]).abs().argsort()[:1]]\n",
    "    radiacion_filtrada = radiacion_filtrada.filter(items=[str(valor_long)])\n",
    "    nivel_radiacion = radiacion_filtrada.iloc[0][str(valor_long)]\n",
    "\n",
    "    #EN ESTA CELDA SE CALCULA LA TC\n",
    "    #Cargo los datos de radiacion\n",
    "    with out2:\n",
    "        print(\"Calculando TC\")\n",
    "\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    regresora = pd.read_csv(os.getcwd()+\"/regresoras.csv\",sep=\";\")\n",
    "\n",
    "    TCarray=[]\n",
    "    RFfinalarray = []\n",
    "\n",
    "    for i in range(0,len(ndvis)):\n",
    "        mediandvizona= ndvis[\"MediaNDVI\"][i]\n",
    "        cultivozona = ndvis[\"CULTIVOS\"][i]\n",
    "\n",
    "\n",
    "        #Selecciono el cultivo\n",
    "        var_cultivo = regresora[regresora['cultivo'] == cultivozona]\n",
    "        pendiente = var_cultivo.iloc[0][\"pendiente\"]\n",
    "        ordenada =  var_cultivo.iloc[0][\"origen\"]\n",
    "\n",
    "        a = 10.07\n",
    "        b = 0.15392254\n",
    "\n",
    "\n",
    "        def calculotc(media_ndvi,RF,pendiente,ordenada):\n",
    "            Rfai = RF*0.48\n",
    "            frFAA = (((1+media_ndvi)/(1-media_ndvi))/a)-b\n",
    "            if frFAA > 0.95:\n",
    "             frfaa = 0.95\n",
    "            RFAA = Rfai*frFAA\n",
    "            TC = ((RFAA*pendiente)+ordenada)*10\n",
    "\n",
    "            TCarray.append(TC)\n",
    "            RFfinalarray.append(RF)\n",
    "            return \n",
    "\n",
    "        calculotc(mediandvizona,nivel_radiacion,pendiente,ordenada)\n",
    "\n",
    "\n",
    "    ndvis[\"TC\"] = TCarray\n",
    "    ndvis[\"RF\"] = RFfinalarray\n",
    "    \n",
    "    \n",
    "    \n",
    "    with out2:\n",
    "        print(\"Armando shapefile\")\n",
    "        \n",
    "    rutafinal = \"temp\"+\"/\"+\"salida1.geojson\"\n",
    "    df = gpd.read_file(rutafinal)\n",
    "    df[\"MediaNDVI\"] = ndvis[\"MediaNDVI\"]\n",
    "    df[\"TC\"] = ndvis[\"TC\"]\n",
    "    df[\"areaHa\"] = ndvis[\"areaHa\"]\n",
    "    \n",
    "    ruta = \"temp/\"+ config.nombrelote +\"_resultados\"\n",
    "    df.to_file(ruta,driver='GeoJSON')\n",
    "    \n",
    "    import ast\n",
    "\n",
    "    ruta = \"temp/\"+ config.nombrelote +\"_resultados\"\n",
    "    f=open(ruta, \"r\")\n",
    "    contents = f.read()\n",
    "    dictionary = ast.literal_eval(contents)\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    from ipywidgets import HTML\n",
    "    from IPython.display import display\n",
    "    import base64\n",
    "\n",
    "    res = json.dumps(dictionary)\n",
    "  \n",
    "\n",
    "    #FILE\n",
    "    filename = config.nombrelote +\"_resultados\"\n",
    "    b64 = base64.b64encode(res.encode())\n",
    "    payload = b64.decode()\n",
    "\n",
    "    #BUTTONS\n",
    "    html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">Descargar</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "\n",
    "    html_button = html_buttons.format(payload=payload,filename=filename)\n",
    "    \n",
    "    \n",
    "    with out2:\n",
    "        clear_output()\n",
    "        print(ndvis)\n",
    "        display(HTML(html_button))\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "boton2.on_click(calcular_tc)\n",
    "HBox([boton2,out2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
